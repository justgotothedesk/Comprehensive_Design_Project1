발표 시작하도록 하겠습니다.
13팀 강의잇나의 2차 중간발표를 맡게 된 신성한 입니다.

오늘 발표의 순서도 이구요,
본격적인 발표를 시작하기 앞서 저희가 제시한 강의잇나 서비스에 대해 간단히 리마인드를 하고 이어가도록 하겠습니다.

강의잇나는 대규모 언어모델 LLm, 즉 챗봇을 기반으로 어떤 수업을 들어야 할지 고민중인 대학생들에게 강의를 추천해주는 서비스입니다. 에브리타임 강의평을 크롤링하여 데이터베이스를 구축하고 이를 바탕으로 사용자가 요구한 조건에 맞는 강의를 추천해주는 방식입니다. 저희 서비스에서 중요한 두가지 키워드가 있는데요 바로 프롬프트 및 컨텍스트 엔지니어링과 벡터 데이터베이스 입니다. 이 두가지에 대한 저희의 결과물은 오늘 발표에서 차차 보여드리는 것으로 하고 먼저 시스템 자체에 대한 최종 설계도를 보여드리겠습니다.

Use case diagram입니다.
왼편에 사용자가 있구요, 사용자는 서비스에 자연어로 질문을 하게됩니다. 본인이 원하는 교수님이나 강의에 관한 질문들이겠죠?
그럼 서비스의 백엔드는 LLM 모델에 질문을 보내줍니다. 이떄 LLM모델은 일반적인 지식이 아닌 저희가 크롤링한 에브리타임 크롤링 자료를 바탕으로 대답을 구성하게 됩니다. 이를 jailbreak라고 합니다. 기존 지식의 틀을 깼다 이런 의미로 받아들일 수 있겠죠?
그럼 LLm모델은 사용자의 질문을 벡터db 레포지토리로 보내어 벡터화 되어있는 크롤링 데이터와 질문을 비교합니다. 이때 벡터db에 대해 설명을 더 드리자면 검색하고자 하는 조건을 벡터화 하여 이미 벡터화 되어 저장 되어있는 데이터 레코드와 비교하여 유사한 레코드를 검색해주는, 말 그대로 벡터 기반의 db입니다. 레포지토리에는 수많은 강의 정보 및 강의평이 담겨있는데 단순히 겹치는 키워드를 찾는 것이 아니라 문장의 의미를 파악하여 유사한 의미의 강의 정보들을 검색한다는 데 벡터db의 의의가 있습니다.
자, 그렇게 얻은 강의 정보들을 다시 llm으로 보내서, 저희가 설계한 컨텍스트와 프롬프트형식에 맞는 문장의 형태로 사용자에게 출력할 수 있도록 리턴합니다.

시스템 구조도의 경우도 use case와 마찬가지의 구조를 갖고있구요.

다음은 최근 저희의 가장 큰 task였던 연구활동 및 논문작성을 위한 주제 선정, 실험과정과 결과를 보여드리도록 하겠습니다. 우선 강의잇나는 대규모 언어모델을 기반으로 서비스를 설계했죠? 강의평에 관한 질의응답을 위해 llm을 사용한 것 인데요. 어떻게 해야 가장 정확하고 효과적인 사용자 경험을 이끌어낼 수 있을지 고민하게 되었습니다.
즉, 어떻게 해야 챗봇이 가장 효율성있는 대답을 하도록 할까 하는 고민이었습니다. 그래서 저희는 키워드 수에 집중하여 몇개의 키워드를 어떻게 입력하면 가장 좋은 대답이 나오는지 연구해보기로 했습니다.

실험환경은 크게 벡터db를 사용한 경우와 그렇지 않은 경우 두가지로 나누었는데 사용하지 않은 경우는 google generative ai studio에서 제공하는 프롬프트 설계 코드를 사용해 챗봇의 대답을 들어보았습니다.

벡터db를 사용하는 경우는 Pg벡터라고 하는 벡터db의 api를 사용해 레포지토리에 접근하여 데이터를 바탕으로 추출된 답변들을 들어보았습니다.

두 케이스 모두 구글 코랩에서 구동하였습니다.

질문은 다음과 같이, 교수명만 담은 질문과 과목명만 담은 질문, 교수명 과목명을 모두 담은 질문을 만들어 추가적인 키워드를 추가해 나가는 방식으로 점점 고차원의 질문을 생성하여 구성했습니다.
추가적으로 여러개의 키워드가 담긴 경우 하나의 문장에 모든 키워드를 담은 케이스와 한 키워드씩 끊어 질문한 케이스로 한 질문을 세분화 했습니다.
또 각 질문마다 optimal한 대답을 저희가 만들어 챗봇의 답변과 코사인 거리를 구해 얼마나 정확한 답변이었는지 측정했습니다.

그 결과인데요, 눈이 좀 아프죠. 보다 알아보기 쉬운 그래프를 보여드리겠습니다.

벡터db를 사용하지 않은 케이스의 막대 그래프입니다. 각 키워드의 구성별로 한 문장 그리고 여러 문장으로 끊은 케이스들의 랭크된 점수를 볼 수 있습니다.

벡터디비를 사용한 사례의 그래프이구요.

간단한 결론을 말씀드리자면 확실히 벡터db를 사용한 경우 평균적으로 정확한 답변을 내는 모습을 볼 수 있었고 특히 케이스별로 정확도의 편차가 가장 적었습니다.
또 문장의 키워드 개수가 3개인 경우 가장 점수가 높았으며 끊어 질문하기보다 한 문장으로 여러 키워드를 같이 질문하는게 결과물이 더 좋았습니다.

지금까지 완료된 저희 작업들을 돌아보면 아직 llm모델의 설계 자체에 매진했기 때문에 흔히 생각하는 챗봇의 프론트엔드를 구현하지 못 했습니다. 따라서 연구 진행에는 원시적인 형태의 챗봇 백엔드의 뼈대로 주요 실험을 진행했다고 할 수 있겠습니다.

이에따라 이전 발표에서 말씀드린 대로 저희가 구축한 챗봇의 뼈대를 바탕으로 웹 서비스를 위한 추가적인 환경 구축 및 학습을 조만간 마무리하여 본격적인 개발을 시작할 예정이며 실험 결과를 기반으로 작성한 논문의 심사가 통과될 시 학회 발표를 준비할 예정입니다.

지금까지 13팀 강의잇나의 발표였습니다.
질문사항 있으시면 말씀해주시면 감사하겠습니다.
