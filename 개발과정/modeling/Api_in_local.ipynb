{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da551797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install vertexai\n",
    "# pip install -U google-cloud-aiplatform --user\n",
    "# pip install transformers\n",
    "# pip install sqlalchemy\n",
    "# pip install mysql-connector-python\n",
    "# install cloud-sql-python-connector[\"pg8000\"] SQLAlchemy==2.0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee364b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to google cloud project \n",
    "import os\n",
    "key_path = 'your api-key.json file path'\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6851c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "PROJECT_ID = \"your project name\"\n",
    "LOCATION = \"your project location\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e9f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.roberta.modeling_roberta.RobertaModel'>\n",
      "<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "# word embedding을 위한 함수\n",
    "import pg8000\n",
    "from google.cloud.sql.connector import Connector, IPTypes\n",
    "import sqlalchemy\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def get_KoSimCSE():\n",
    "    model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta-multitask')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta-multitask')\n",
    "\n",
    "    print(type(model))\n",
    "    print(type(tokenizer))\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = get_KoSimCSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ea9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorDB 연결\n",
    "instance_connection_name = \"your_instance_name\"\n",
    "db_user = \"db_name\"\n",
    "db_pass = \"your_db_password\"\n",
    "db_name = \"your_vector_DB_name\"\n",
    "\n",
    "# initialize Cloud SQL Python Connector object\n",
    "connector = Connector()\n",
    "\n",
    "def getconn() -> pg8000.dbapi.Connection:\n",
    "    conn: pg8000.dbapi.Connection = connector.connect(\n",
    "        instance_connection_name,\n",
    "        \"pg8000\",\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        db=db_name,\n",
    "        ip_type=IPTypes.PUBLIC,\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "pool = sqlalchemy.create_engine(\n",
    "    \"postgresql+pg8000://\",\n",
    "    creator=getconn,\n",
    ")\n",
    "\n",
    "with pool.connect() as db_conn:\n",
    "  db_conn.execute(\n",
    "      sqlalchemy.text(\n",
    "          \"CREATE EXTENSION IF NOT EXISTS vector with schema public\"\n",
    "      )\n",
    "  )\n",
    "  db_conn.commit()\n",
    "\n",
    "# pool.connect()하고 한 transaction만 수행 가능함.\n",
    "# transaction 하나 수행하고 commit, close 하고 다시 connect 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0dd632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'vertexai.preview.language_models._PreviewChatModel'>\n",
      "과목명 NULL 교수명 김정근\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import ChatModel, InputOutputTextPair\n",
    "# TextGenerationModel, InputOutputTextPair, TextEmbeddingModel\n",
    "\n",
    "query_text = input()\n",
    "\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")  #chat model 불러오기\n",
    "print(type(chat_model))\n",
    "\n",
    "chat = chat_model.start_chat(\n",
    "    context=\"수업에 대해 궁금해하는 학생들이 과목, 교수에 대해 질문하는 서비스야\",\n",
    "    examples=[\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"정기숙 교수님 자료구조응용 수업 어때?에서 과목명, 교수명이 뭐야?\",\n",
    "            output_text=\"과목명 자료구조응용 교수명 정기숙\",\n",
    "        ),\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"정기숙 교수님 어때?에서 과목명, 교수명이 뭐야?\",\n",
    "            output_text=\"과목명 NULL 교수명 정기숙\",\n",
    "        ),\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"자료구조응용 수업 어때?에서 과목명, 교수명이 뭐야?\",\n",
    "            output_text=\"과목명 자료구조응용 교수명 NULL\",\n",
    "        ),\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    max_output_tokens=1024,\n",
    "    top_p=0.8,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "#LLM에게 질문해서 user의 input으로부터 과목, 교수명 가져오기\n",
    "key_query = chat.send_message(query_text+\"에서 과목명, 교수명이 뭐야?\").text\n",
    "print(key_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0f4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(q): #LLM의 output으로부터 prof name, lecture name 추출\n",
    "  lec = q.find(\"과목명\")\n",
    "  prof = q.find(\"교수명\")\n",
    "  lecture = q[lec+4:prof-1]\n",
    "  professor = q[prof+4:]\n",
    "  if lecture == \"NULL\" : lecture = None\n",
    "  if professor == \"NULL\" : professor = None\n",
    "  return lecture, professor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28590e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(query_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "embeddings, _ = model(**inputs, return_dict=False)\n",
    "embedding_arr = embeddings[0][0].detach().numpy()\n",
    "embedding_str = \",\".join(str(x) for x in embedding_arr)\n",
    "embedding_str = \"[\"+embedding_str+\"]\"\n",
    "\n",
    "lec, prof = extract(key_query)\n",
    "if lec != None and prof != None :    #User의 질문 유형에 맞게 쿼리문 짜줌\n",
    "  insert_stat, param = (sqlalchemy.text(\n",
    "            \"\"\"SELECT origin_text FROM PROFNLEC WHERE INFO LIKE :information\n",
    "              ORDER BY v <-> :query_vec LIMIT 20\"\"\"\n",
    "  ), {\"information\": f'%{lec}%{prof}%', \"query_vec\": embedding_str})\n",
    "elif lec != None :\n",
    "  insert_stat, param = sqlalchemy.text(\n",
    "            \"\"\"SELECT origin_text FROM PROFNLEC WHERE INFO LIKE :lecture\n",
    "              ORDER BY v <-> :query_vec LIMIT 20\"\"\"\n",
    "  ), {\"lecture\": f'%{lec}%', \"query_vec\": embedding_str}\n",
    "elif prof != None :\n",
    "  insert_stat, param = sqlalchemy.text(\n",
    "            \"\"\"SELECT origin_text FROM PROFNLEC WHERE INFO LIKE :professor\n",
    "              ORDER BY v <-> :query_vec LIMIT 20\"\"\"\n",
    "  ), {\"professor\": f'%{prof}%', \"query_vec\": embedding_str}\n",
    "\n",
    "with pool.connect() as db_conn: # 쿼리 실행문\n",
    "    result = db_conn.execute(\n",
    "        insert_stat, parameters = param\n",
    "    ).fetchall()\n",
    "\n",
    "#query 결과를 문자열로 바꾸기 <- Context에는 문자열만 들어갈 수 있음\n",
    "articles = \"\"\n",
    "for res in result :\n",
    "  articles += res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a69e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김정근 교수님은 열정적인 교수님이지만 초임 교수님이라 강의력이 부족하다는 평이 있다. 과목이 어렵고 과제가 많지만 교수님이 친절하고 학생들을 많이 배려해준다고 한다.\n"
     ]
    }
   ],
   "source": [
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
    "\n",
    "output_chat = chat_model.start_chat(\n",
    "    context=\"강의를 찾는 대학생들에게 강의평들을 토대로 수업이 어떤지 알려주는 서비스야, 주어진 강의평들을 요약해서 학생들에게 알려줘\" + articles + \"강의평을 가져올 때는 있는 그대로 가져오지 말고 나름대로 요약해서 알려줘\",\n",
    "    temperature=0.3,\n",
    "    max_output_tokens=1024,\n",
    "    top_p=0.8,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "sentences = []\n",
    "output = output_chat.send_message(query_text).text\n",
    "sentences.append(output)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
